{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPor defecto, keras tira de GPU\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras\n",
    "'''\n",
    "Por defecto, keras tira de GPU\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X_train --> 60 000 fotos, cada una tiene 28x28 pixels   y_train --> 60 000 etiquetas\n",
    "\n",
    "foto_0 -------> 0\n",
    "foto_1 -------> 0\n",
    "foto_2 -------> 0\n",
    "foto_3 -------> 1\n",
    "foto_4 -------> 1\n",
    "foto_5 -------> 3\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x241f98f7d08>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data (these are NumPy arrays). Aplano a una dimension cada imagen.\n",
    "# Escalamos ya que vamos a usar gradient descent, y le afecta mucho la escala de las features.\n",
    "# Ejecutar esta celda solo una vez. Si no, reescalará\n",
    "\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Reserve 10,000 samples for validation. Entraran dentro del modelo para validar. No es validacion cruzada\n",
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "print(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una manera de declarar la red neuronal\n",
    "\n",
    "# Siempre hay que declarar la capa sequential para empezar a declarar la red\n",
    "# Se trata de la API sequential\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Flatten, aplana en un unico vector. Y especificamos el tamaño de la entrada\n",
    "# Es como si hiciese un .reshape(-1, 28*28)\n",
    "# \"kernel_initializer\" o \"bias_initializer\" No lo usamos pero seria para inicializar los pesos de otra manera\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "\n",
    "# Capas de la red. Dense es la capa de neuronas. Necesitamos numero y activacion\n",
    "model.add(keras.layers.Dense(units = 300, activation = 'relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "\n",
    "# Capa de salida, con tamaño del número de clases\n",
    "# Suele ir aqui un softmax. Para multiclase guay. Si es binaria -> sigmoide\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "    ]\n",
    "    \n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.dense.Dense object at 0x00000241F93493C8>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.flatten.Flatten at 0x24180127c08>,\n",
       " <keras.layers.core.dense.Dense at 0x241f93493c8>,\n",
       " <keras.layers.core.dense.Dense at 0x24180127e88>,\n",
       " <keras.layers.core.dense.Dense at 0x241f9922c48>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.layers[1])\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()\n",
    "\n",
    "# 784 features (pixeles de las imagenes) x 300 neuronas\n",
    "# Los pesos están inicializados aleatoriamente\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se especifica la configuración del entrenamiento (optimizador, pérdida, métricas):\n",
    "model.compile(\n",
    "    # Stocastic gradient descent. El algoritmo para minimizar la loss function\n",
    "    # El stocastic va haciendo muestreo en cada evaluacion, no usa todo.\n",
    "    # Podemos modificar el learning rate(0.01 por defecto) mediante el parametro lr\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    \n",
    "    \n",
    "    # Loss function to minimize\n",
    "    # sparse_categorical_crossentropy cuando tenemos un label en nuna columna\n",
    "    # Si lo tuviesemos en varias tipo dummy, cogeriamos categorical_crossentropy\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    \n",
    "    \n",
    "    # List of metrics to monitor\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "\n",
    ")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(optimizer='sgd',\n",
    "loss= \"sparse_categorical_crossentropy\",\n",
    "metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "# La primera hidden layer tiene 784 entradas x 300 salidas\n",
    "# Son los 235500 params = 783x300 + 300 (bias)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/15\n",
      "782/782 [==============================] - 42s 43ms/step - loss: 0.9507 - accuracy: 0.7605 - val_loss: 0.4060 - val_accuracy: 0.8955\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.3803 - accuracy: 0.8954 - val_loss: 0.3043 - val_accuracy: 0.9174\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.3109 - accuracy: 0.9123 - val_loss: 0.2702 - val_accuracy: 0.9240\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.2757 - accuracy: 0.9214 - val_loss: 0.2428 - val_accuracy: 0.9313\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.2508 - accuracy: 0.9282 - val_loss: 0.2256 - val_accuracy: 0.9383\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.2311 - accuracy: 0.9345 - val_loss: 0.2245 - val_accuracy: 0.9362\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 0.2146 - accuracy: 0.9383 - val_loss: 0.1980 - val_accuracy: 0.9465\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.2005 - accuracy: 0.9433 - val_loss: 0.1869 - val_accuracy: 0.9481\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.1878 - accuracy: 0.9467 - val_loss: 0.1749 - val_accuracy: 0.9536\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 0.1765 - accuracy: 0.9500 - val_loss: 0.1706 - val_accuracy: 0.9540\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 0.1668 - accuracy: 0.9526 - val_loss: 0.1609 - val_accuracy: 0.9562\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.1576 - accuracy: 0.9546 - val_loss: 0.1535 - val_accuracy: 0.9583\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.1498 - accuracy: 0.9567 - val_loss: 0.1471 - val_accuracy: 0.9605\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.1423 - accuracy: 0.9589 - val_loss: 0.1431 - val_accuracy: 0.9607\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.1357 - accuracy: 0.9612 - val_loss: 0.1387 - val_accuracy: 0.9622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEn el entreanamiento solo hay que fijarse que el loss va para abajo, es bueno.\\nSi vemos que ya no baja mas, no serán necesarias tantas epochs.\\nImprimera tantas lineas como epochs hayamos puesto\\n\\nTampoco usamos el class_weight, que le da más peso a las clases con pocas muestras\\nUtil para datasets desbalanceados.\\n\\nEl loss que muestra es el categoricalcrossentropy\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamos el modelo con un batch_size de 64 imágenes por cada iteración, 10 epochs y especificando cuál es el conjunto de validación.\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=15,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "\n",
    "'''\n",
    "En el entreanamiento solo hay que fijarse que el loss va para abajo, es bueno.\n",
    "Si vemos que ya no baja mas, no serán necesarias tantas epochs.\n",
    "Imprimera tantas lineas como epochs hayamos puesto\n",
    "\n",
    "Tampoco usamos el class_weight, que le da más peso a las clases con pocas muestras\n",
    "Util para datasets desbalanceados.\n",
    "\n",
    "El loss que muestra es el categoricalcrossentropy\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    # En vez de validation data podemos usar el argumento validation_split=0.1\n",
    "    \n",
    "\n",
    "'''\n",
    "En el entreanamiento solo hay que fijarse que el loss va para abajo, es bueno.\n",
    "Si vemos que ya no baja mas, no serán necesarias tantas epochs.\n",
    "Imprimera tantas lineas como epochs hayamos puesto\n",
    "\n",
    "Tampoco usamos el class_weight, que le da más peso a las clases con pocas muestras\n",
    "Util para datasets desbalanceados.\n",
    "\n",
    "El loss que muestra es el categoricalcrossentropy\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.1294 - accuracy: 0.9630 - val_loss: 0.1375 - val_accuracy: 0.9619\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.1237 - accuracy: 0.9647 - val_loss: 0.1314 - val_accuracy: 0.9635\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.1182 - accuracy: 0.9663 - val_loss: 0.1266 - val_accuracy: 0.9656\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.1131 - accuracy: 0.9681 - val_loss: 0.1238 - val_accuracy: 0.9662\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 14s 17ms/step - loss: 0.1086 - accuracy: 0.9696 - val_loss: 0.1218 - val_accuracy: 0.9676\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.1040 - accuracy: 0.9704 - val_loss: 0.1177 - val_accuracy: 0.9677\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.0997 - accuracy: 0.9721 - val_loss: 0.1144 - val_accuracy: 0.9685\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.0961 - accuracy: 0.9734 - val_loss: 0.1127 - val_accuracy: 0.9691\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.0924 - accuracy: 0.9742 - val_loss: 0.1098 - val_accuracy: 0.9686\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.0889 - accuracy: 0.9754 - val_loss: 0.1086 - val_accuracy: 0.9683\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.0856 - accuracy: 0.9766 - val_loss: 0.1052 - val_accuracy: 0.9706\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.0826 - accuracy: 0.9770 - val_loss: 0.1056 - val_accuracy: 0.9698\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 14s 17ms/step - loss: 0.0797 - accuracy: 0.9775 - val_loss: 0.1021 - val_accuracy: 0.9699\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.0766 - accuracy: 0.9786 - val_loss: 0.0996 - val_accuracy: 0.9708\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0741 - accuracy: 0.9797 - val_loss: 0.0986 - val_accuracy: 0.9716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x241813b2f08>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=15,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 15, 'steps': 782}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.9506812691688538,\n",
       "  0.3803235590457916,\n",
       "  0.31086158752441406,\n",
       "  0.27570241689682007,\n",
       "  0.2508331537246704,\n",
       "  0.23114028573036194,\n",
       "  0.21457310020923615,\n",
       "  0.20047087967395782,\n",
       "  0.18781138956546783,\n",
       "  0.17650751769542694,\n",
       "  0.16683945059776306,\n",
       "  0.1576365828514099,\n",
       "  0.1497552990913391,\n",
       "  0.1423010230064392,\n",
       "  0.1357221156358719],\n",
       " 'accuracy': [0.7605400085449219,\n",
       "  0.8954200148582458,\n",
       "  0.9123200178146362,\n",
       "  0.9214400053024292,\n",
       "  0.9282400012016296,\n",
       "  0.9345399737358093,\n",
       "  0.9383400082588196,\n",
       "  0.9432600140571594,\n",
       "  0.9467200040817261,\n",
       "  0.9500200152397156,\n",
       "  0.9525600075721741,\n",
       "  0.9546200037002563,\n",
       "  0.9567000269889832,\n",
       "  0.958899974822998,\n",
       "  0.9611600041389465],\n",
       " 'val_loss': [0.4060216248035431,\n",
       "  0.3042948246002197,\n",
       "  0.2701966464519501,\n",
       "  0.24278606474399567,\n",
       "  0.2256477326154709,\n",
       "  0.2244776338338852,\n",
       "  0.19801995158195496,\n",
       "  0.1868835687637329,\n",
       "  0.17490530014038086,\n",
       "  0.17059236764907837,\n",
       "  0.16094276309013367,\n",
       "  0.15345034003257751,\n",
       "  0.14708887040615082,\n",
       "  0.14309915900230408,\n",
       "  0.1386779397726059],\n",
       " 'val_accuracy': [0.8955000042915344,\n",
       "  0.9174000024795532,\n",
       "  0.9240000247955322,\n",
       "  0.9312999844551086,\n",
       "  0.9383000135421753,\n",
       "  0.9362000226974487,\n",
       "  0.9465000033378601,\n",
       "  0.9480999708175659,\n",
       "  0.9535999894142151,\n",
       "  0.9539999961853027,\n",
       "  0.9562000036239624,\n",
       "  0.958299994468689,\n",
       "  0.9605000019073486,\n",
       "  0.9606999754905701,\n",
       "  0.9621999859809875]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Podemos ver como evoluciona el entrenamiento, en funcion de los epochs\n",
    "# Validacion y training estan muy cerca, no hay overfitting!\n",
    "# Todavia no ha acabado de coverger ya que el loss en validacion sigue bajando,\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0974 - accuracy: 0.9712\n",
      "test loss, test acc: [0.09737644344568253, 0.9711999893188477]\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos el \"score\" a partir del conjunto de test\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "\n",
    "# Metodo evaluate para que nos de el error vs las metricas elegidas en la funcion compile\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.001, 0.002, 0.   , 0.   , 0.   , 0.997, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Ojo aqui viene slicing xq presupone que le entran varios inputs\n",
    "Nos da las probabilidades de pertenecer a una clase u otra.\n",
    "'''\n",
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.997"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 7s 16ms/step - loss: 2.6729 - val_loss: 0.6195\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.4314 - val_loss: 0.6716\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.4074 - val_loss: 0.4097\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3912 - val_loss: 0.3975\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3789 - val_loss: 0.4174\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 6s 15ms/step - loss: 0.3752 - val_loss: 0.3790\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3707 - val_loss: 0.3834\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3643 - val_loss: 0.3786\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.4078 - val_loss: 0.3805\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3615 - val_loss: 0.3836\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.3575 - val_loss: 0.3735\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 5s 14ms/step - loss: 0.3557 - val_loss: 0.3646\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.3610 - val_loss: 0.3688\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3692 - val_loss: 0.3648\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3523 - val_loss: 0.3666\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3578 - val_loss: 0.3586\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3847 - val_loss: 0.3885\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.4021 - val_loss: 0.3657\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3778 - val_loss: 0.4060\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3508 - val_loss: 0.3571\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.3492\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    # No hace falta capa de flatten. No hay que aplanar ninguna imagen\n",
    "    keras.layers.Dense(30, activation=\"relu\",\n",
    "                       input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1) # una unica neurona de salida\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=\"sgd\")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Sirven para que el modelo se vaya guardando tras cada epoch, asi no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 4s 7ms/step - loss: 0.3494\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3467\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3406\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3348\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3403\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3450\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.3325\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 5s 12ms/step - loss: 0.3307\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3291\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.3546\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 6s 15ms/step - loss: 0.3294 - val_loss: 0.3468\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.3321 - val_loss: 0.3379\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 7s 19ms/step - loss: 0.3610 - val_loss: 0.3380\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 6s 17ms/step - loss: 0.3282 - val_loss: 0.3459\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3386 - val_loss: 0.3963\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.3248 - val_loss: 0.3428\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 5s 14ms/step - loss: 0.3489 - val_loss: 0.3413\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.3265 - val_loss: 0.3413\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3228 - val_loss: 0.3380\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3209 - val_loss: 0.3366\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3216 - val_loss: 0.3344\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3210 - val_loss: 0.3335\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3196 - val_loss: 0.3516\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3177 - val_loss: 0.3344\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3168 - val_loss: 0.3328\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3204 - val_loss: 0.6729\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3669 - val_loss: 1.0777\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.8513 - val_loss: 0.3664\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3410 - val_loss: 0.3569\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3418 - val_loss: 0.3610\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.3332 - val_loss: 0.3497\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3291 - val_loss: 0.3463\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 5s 14ms/step - loss: 0.3258 - val_loss: 0.3472\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.3228 - val_loss: 0.3411\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3211 - val_loss: 0.3409\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3191 - val_loss: 0.3388\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3183 - val_loss: 0.3370\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3158 - val_loss: 0.3380\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3144 - val_loss: 0.3382\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3157 - val_loss: 0.3321\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3149 - val_loss: 0.3344\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3124 - val_loss: 0.3373\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3117 - val_loss: 0.3317\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3125 - val_loss: 0.3385\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3152 - val_loss: 0.3325\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3122 - val_loss: 0.3308\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3103 - val_loss: 0.3312\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3101 - val_loss: 0.3280\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3091 - val_loss: 0.3295\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3104 - val_loss: 0.3321\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3093 - val_loss: 0.3290\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3127 - val_loss: 0.3333\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3118 - val_loss: 0.3410\n"
     ]
    }
   ],
   "source": [
    "# 10 esta bien. Lo pondemos a 5 para el ejercicio\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, \n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard\n",
    "Keras tiene implementado un dashboard para monitorizar las ejecuciones del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Crea este directorio\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "# Guarda una carpeta nueva con la fecha de la ejecucion\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3104 - val_loss: 0.3264\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3097 - val_loss: 0.3289\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3085 - val_loss: 0.3326\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.3076 - val_loss: 0.3303\n",
      "Epoch 5/50\n",
      "363/363 [==============================] - 5s 15ms/step - loss: 0.3096 - val_loss: 0.3279\n",
      "Epoch 6/50\n",
      "363/363 [==============================] - 5s 14ms/step - loss: 0.3177 - val_loss: 0.3416\n",
      "Epoch 7/50\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.3118 - val_loss: 0.3452\n",
      "Epoch 8/50\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3097 - val_loss: 0.3312\n",
      "Epoch 9/50\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3075 - val_loss: 0.3363\n",
      "Epoch 10/50\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3091 - val_loss: 0.3297\n",
      "Epoch 11/50\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3073 - val_loss: 0.3339\n",
      "Epoch 12/50\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3075 - val_loss: 0.3351\n",
      "Epoch 13/50\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3065 - val_loss: 0.3391\n",
      "Epoch 14/50\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3082 - val_loss: 0.3288\n",
      "Epoch 15/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3068 - val_loss: 0.3335\n",
      "Epoch 16/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3058 - val_loss: 0.3275\n",
      "Epoch 17/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3053 - val_loss: 0.3303\n",
      "Epoch 18/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3064 - val_loss: 0.3282\n",
      "Epoch 19/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3057 - val_loss: 0.3259\n",
      "Epoch 20/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3056 - val_loss: 0.3298\n",
      "Epoch 21/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3044 - val_loss: 0.3245\n",
      "Epoch 22/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3040 - val_loss: 0.3256\n",
      "Epoch 23/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3046 - val_loss: 0.3219\n",
      "Epoch 24/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3034 - val_loss: 0.3247\n",
      "Epoch 25/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3025 - val_loss: 0.3274\n",
      "Epoch 26/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3028 - val_loss: 0.3346\n",
      "Epoch 27/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3028 - val_loss: 0.3206\n",
      "Epoch 28/50\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3023 - val_loss: 0.3228\n",
      "Epoch 29/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3015 - val_loss: 0.3271\n",
      "Epoch 30/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3023 - val_loss: 0.3222\n",
      "Epoch 31/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3010 - val_loss: 0.3224\n",
      "Epoch 32/50\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3018 - val_loss: 0.3287\n",
      "Epoch 33/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3026 - val_loss: 0.3237\n",
      "Epoch 34/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3013 - val_loss: 0.3231\n",
      "Epoch 35/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3020 - val_loss: 0.3227\n",
      "Epoch 36/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3017 - val_loss: 0.3249\n",
      "Epoch 37/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3014 - val_loss: 0.3240\n",
      "Epoch 38/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3005 - val_loss: 0.3264\n",
      "Epoch 39/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3003 - val_loss: 0.3221\n",
      "Epoch 40/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3000 - val_loss: 0.3194\n",
      "Epoch 41/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3006 - val_loss: 0.3205\n",
      "Epoch 42/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3015 - val_loss: 0.3189\n",
      "Epoch 43/50\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3000 - val_loss: 0.3193\n",
      "Epoch 44/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3006 - val_loss: 0.3188\n",
      "Epoch 45/50\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.2993 - val_loss: 0.3159\n",
      "Epoch 46/50\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2986 - val_loss: 0.3202\n",
      "Epoch 47/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.2994 - val_loss: 0.3217\n",
      "Epoch 48/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2994 - val_loss: 0.3339\n",
      "Epoch 49/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2990 - val_loss: 0.3212\n",
      "Epoch 50/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.2986 - val_loss: 0.3156\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPara lanzarlo desde el jupyter notebook\\n%load_ext tensorboard\\n%tensorboard --logdir=./my_logs --port=6006\\n\\nPara lanzarlo desde el terminal, hay que estar en la carpeta de los logs\\ntensorboard --logdir=./my_logs --port=6006\\n\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Para lanzarlo desde el jupyter notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "Para lanzarlo desde el terminal, hay que estar en la carpeta de los logs\n",
    "tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 22404), started 1 day, 15:40:48 ago. (Use '!kill 22404' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8cc26bf790b33bd1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8cc26bf790b33bd1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
