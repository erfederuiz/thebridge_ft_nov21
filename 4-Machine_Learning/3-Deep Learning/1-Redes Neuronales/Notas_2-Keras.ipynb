{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPor defecto, keras tira de GPU\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Por defecto, keras tira de GPU\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f2481d0948>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data (these are NumPy arrays). Aplano a una dimension cada imagen.\n",
    "# Escalamos ya que vamos a usar gradient descent, y le afecta mucho la escala de las features.\n",
    "# Ejecutar esta celda solo una vez. Si no, reescalará\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Reserve 10,000 samples for validation. Entraran dentro del modelo para validar. No es validacion cruzada\n",
    "\n",
    "\n",
    "print(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una manera de declarar la red neuronal\n",
    "\n",
    "# Siempre hay que declarar la capa sequential para empezar a declarar la red\n",
    "# Se trata de la API sequential\n",
    "\n",
    "\n",
    "# Flatten, aplana en un unico vector. Y especificamos el tamaño de la entrada\n",
    "# Es como si hiciese un .reshape(-1, 28*28)\n",
    "# \"kernel_initializer\" o \"bias_initializer\" No lo usamos pero seria para inicializar los pesos de otra manera\n",
    "\n",
    "\n",
    "# Capas de la red. Dense es la capa de neuronas. Necesitamos numero y activacion\n",
    "\n",
    "\n",
    "\n",
    "# Capa de salida, con tamaño del número de clases\n",
    "# Suele ir aqui un softmax. Para multiclase guay. Si es binaria -> sigmoide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001F24728CE88>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x1f24728c188>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1f24728ce88>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1f247292288>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1f247292648>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.layers[1])\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 784 features (pixeles de las imagenes) x 300 neuronas\n",
    "# Los pesos están inicializados aleatoriamente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se especifica la configuración del entrenamiento (optimizador, pérdida, métricas):\n",
    "\n",
    "    # Stocastic gradient descent. El algoritmo para minimizar la loss function\n",
    "    # El stocastic va haciendo muestreo en cada evaluacion, no usa todo.\n",
    "    # Podemos modificar el learning rate(0.01 por defecto) mediante el parametro lr\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Loss function to minimize\n",
    "    # sparse_categorical_crossentropy cuando tenemos un label en nuna columna\n",
    "    # Si lo tuviesemos en varias tipo dummy, cogeriamos categorical_crossentropy\n",
    "    \n",
    "    \n",
    "    # List of metrics to monitor\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "# La primera hidden layer tiene 784 entradas x 300 salidas\n",
    "# Son los 235500 params = 783x300 + 300 (bias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 1.4043 - accuracy: 0.6287 - val_loss: 0.4015 - val_accuracy: 0.8961\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4091 - accuracy: 0.8892 - val_loss: 0.3132 - val_accuracy: 0.9135\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.3261 - accuracy: 0.9105 - val_loss: 0.2685 - val_accuracy: 0.9264\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.2795 - accuracy: 0.9198 - val_loss: 0.2442 - val_accuracy: 0.9311\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.2617 - accuracy: 0.9271 - val_loss: 0.2314 - val_accuracy: 0.9326\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.2329 - accuracy: 0.9351 - val_loss: 0.2105 - val_accuracy: 0.9414\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.2165 - accuracy: 0.9398 - val_loss: 0.1960 - val_accuracy: 0.9455\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.2043 - accuracy: 0.9420 - val_loss: 0.1868 - val_accuracy: 0.9491\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1913 - accuracy: 0.9452 - val_loss: 0.1776 - val_accuracy: 0.9519\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1765 - accuracy: 0.9494 - val_loss: 0.1679 - val_accuracy: 0.9538\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1724 - accuracy: 0.9513 - val_loss: 0.1616 - val_accuracy: 0.9557\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1635 - accuracy: 0.9536 - val_loss: 0.1534 - val_accuracy: 0.9587\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1470 - accuracy: 0.9573 - val_loss: 0.1498 - val_accuracy: 0.9606\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1416 - accuracy: 0.9614 - val_loss: 0.1439 - val_accuracy: 0.9605\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1365 - accuracy: 0.9629 - val_loss: 0.1358 - val_accuracy: 0.9633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEn el entreanamiento solo hay que fijarse que el loss va para abajo, es bueno.\\nSi vemos que ya no baja mas, no serán necesarias tantas epochs.\\nImprimera tantas lineas como epochs hayamos puesto\\n\\nTampoco usamos el class_weight, que le da más peso a las clases con pocas muestras\\nUtil para datasets desbalanceados.\\n\\nEl loss que muestra es el categoricalcrossentropy\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamos el modelo con un batch_size de 64 imágenes por cada iteración, 10 epochs y especificando cuál es el conjunto de validación.\n",
    "\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    # En vez de validation data podemos usar el argumento validation_split=0.1\n",
    "    \n",
    "\n",
    "'''\n",
    "En el entreanamiento solo hay que fijarse que el loss va para abajo, es bueno.\n",
    "Si vemos que ya no baja mas, no serán necesarias tantas epochs.\n",
    "Imprimera tantas lineas como epochs hayamos puesto\n",
    "\n",
    "Tampoco usamos el class_weight, que le da más peso a las clases con pocas muestras\n",
    "Util para datasets desbalanceados.\n",
    "\n",
    "El loss que muestra es el categoricalcrossentropy\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1281 - accuracy: 0.9639 - val_loss: 0.1335 - val_accuracy: 0.9631\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1221 - accuracy: 0.9660 - val_loss: 0.1278 - val_accuracy: 0.9662\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1166 - accuracy: 0.9671 - val_loss: 0.1261 - val_accuracy: 0.9656\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.1113 - accuracy: 0.9692 - val_loss: 0.1223 - val_accuracy: 0.9678\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1065 - accuracy: 0.9704 - val_loss: 0.1192 - val_accuracy: 0.9680\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1020 - accuracy: 0.9714 - val_loss: 0.1156 - val_accuracy: 0.9678\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.0977 - accuracy: 0.9732 - val_loss: 0.1170 - val_accuracy: 0.9673\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0938 - accuracy: 0.9742 - val_loss: 0.1144 - val_accuracy: 0.9683\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0902 - accuracy: 0.9753 - val_loss: 0.1079 - val_accuracy: 0.9708\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.0868 - accuracy: 0.9758 - val_loss: 0.1070 - val_accuracy: 0.9706\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0835 - accuracy: 0.9768 - val_loss: 0.1055 - val_accuracy: 0.9701\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.0804 - accuracy: 0.9782 - val_loss: 0.1048 - val_accuracy: 0.9718\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0775 - accuracy: 0.9786 - val_loss: 0.1010 - val_accuracy: 0.9727\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.0747 - accuracy: 0.9797 - val_loss: 0.0986 - val_accuracy: 0.9723\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0721 - accuracy: 0.9803 - val_loss: 0.0998 - val_accuracy: 0.9727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f2477de588>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 15, 'steps': 782}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.9049946665763855,\n",
       "  0.3779575824737549,\n",
       "  0.3125596046447754,\n",
       "  0.2782071530818939,\n",
       "  0.25314468145370483,\n",
       "  0.23330585658550262,\n",
       "  0.21643804013729095,\n",
       "  0.20227639377117157,\n",
       "  0.18928885459899902,\n",
       "  0.17794933915138245,\n",
       "  0.16746218502521515,\n",
       "  0.15794992446899414,\n",
       "  0.14947766065597534,\n",
       "  0.14172479510307312,\n",
       "  0.1346474438905716],\n",
       " 'accuracy': [0.7793599963188171,\n",
       "  0.8961799740791321,\n",
       "  0.9121400117874146,\n",
       "  0.9218400120735168,\n",
       "  0.9294999837875366,\n",
       "  0.9351599812507629,\n",
       "  0.9390000104904175,\n",
       "  0.9430999755859375,\n",
       "  0.9464600086212158,\n",
       "  0.9498199820518494,\n",
       "  0.9525200128555298,\n",
       "  0.9550399780273438,\n",
       "  0.9575600028038025,\n",
       "  0.9606599807739258,\n",
       "  0.9627799987792969],\n",
       " 'val_loss': [0.40149006247520447,\n",
       "  0.3132224977016449,\n",
       "  0.2685086131095886,\n",
       "  0.2441762238740921,\n",
       "  0.2314123958349228,\n",
       "  0.21050550043582916,\n",
       "  0.19604787230491638,\n",
       "  0.18681855499744415,\n",
       "  0.17764200270175934,\n",
       "  0.16790638864040375,\n",
       "  0.1616002768278122,\n",
       "  0.15338660776615143,\n",
       "  0.14981839060783386,\n",
       "  0.14389236271381378,\n",
       "  0.13576841354370117],\n",
       " 'val_accuracy': [0.8960999846458435,\n",
       "  0.9135000109672546,\n",
       "  0.9264000058174133,\n",
       "  0.9311000108718872,\n",
       "  0.9326000213623047,\n",
       "  0.9413999915122986,\n",
       "  0.9455000162124634,\n",
       "  0.9491000175476074,\n",
       "  0.9519000053405762,\n",
       "  0.9538000226020813,\n",
       "  0.9556999802589417,\n",
       "  0.9587000012397766,\n",
       "  0.9606000185012817,\n",
       "  0.9605000019073486,\n",
       "  0.9632999897003174]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Podemos ver como evoluciona el entrenamiento, en funcion de los epochs\n",
    "# Validacion y training estan muy cerca, no hay overfitting!\n",
    "# Todavia no ha acabado de coverger ya que el loss en validacion sigue bajando,\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9693\n",
      "test loss, test acc: [0.09903569519519806, 0.9692999720573425]\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos el \"score\" a partir del conjunto de test\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "\n",
    "# Metodo evaluate para que nos de el error vs las metricas elegidas en la funcion compile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.001, 0.007, 0.   , 0.   , 0.   , 0.991, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Ojo aqui viene slicing xq presupone que le entran varios inputs\n",
    "Nos da las probabilidades de pertenecer a una clase u otra.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.991"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.6018 - val_loss: 4.9579\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 916us/step - loss: 0.7970 - val_loss: 0.4317\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 933us/step - loss: 0.4177 - val_loss: 0.3949\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 832us/step - loss: 0.4068 - val_loss: 0.3770\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 869us/step - loss: 0.3717 - val_loss: 0.3702\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.3791 - val_loss: 0.3623\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 938us/step - loss: 0.3803 - val_loss: 0.3687\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5269 - val_loss: 0.3590\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3706 - val_loss: 0.3525\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3538 - val_loss: 0.3505\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 0.3497\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 960us/step - loss: 0.3453 - val_loss: 0.3454\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 889us/step - loss: 0.3475 - val_loss: 0.3496\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 908us/step - loss: 0.3501 - val_loss: 0.3446\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 903us/step - loss: 0.3444 - val_loss: 0.3422\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 925us/step - loss: 0.3344 - val_loss: 0.3428\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 930us/step - loss: 0.3460 - val_loss: 0.3400\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 908us/step - loss: 0.3405 - val_loss: 0.3468\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.3465 - val_loss: 0.3388\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 934us/step - loss: 0.3369 - val_loss: 0.3360\n",
      "162/162 [==============================] - 0s 589us/step - loss: 0.3678\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    # No hace falta capa de flatten. No hay que aplanar ninguna imagen\n",
    "    keras.layers.Dense(30, activation=\"relu\",\n",
    "                       input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1) # una unica neurona de salida\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=\"sgd\")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Sirven para que el modelo se vaya guardando tras cada epoch, asi no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 676us/step - loss: 0.3415\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 725us/step - loss: 0.3359\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 811us/step - loss: 0.3341\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 739us/step - loss: 0.3323\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 807us/step - loss: 0.3311\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 841us/step - loss: 0.3302\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 745us/step - loss: 0.3301\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 725us/step - loss: 0.3287\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 801us/step - loss: 0.3285\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 777us/step - loss: 0.3280\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3262 - val_loss: 0.3306\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3245 - val_loss: 0.3302\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3239 - val_loss: 0.3271\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3268 - val_loss: 0.3254\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3219 - val_loss: 0.3236\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3216 - val_loss: 0.3228\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3203 - val_loss: 0.3234\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3196 - val_loss: 0.3230\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3182 - val_loss: 0.3199\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3215 - val_loss: 0.3251\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3188 - val_loss: 0.3173\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 976us/step - loss: 0.3157 - val_loss: 0.3233\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3158 - val_loss: 0.3234\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3139 - val_loss: 0.3196\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3120 - val_loss: 0.3181\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3119 - val_loss: 0.3146\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3102 - val_loss: 0.3158\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3120 - val_loss: 0.3151\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3111 - val_loss: 0.3130\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3131 - val_loss: 0.3112\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3069 - val_loss: 0.3168\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3077 - val_loss: 0.3151\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3086 - val_loss: 0.3094\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3125 - val_loss: 0.3234\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3043 - val_loss: 0.3211\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3047 - val_loss: 0.3295\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3042 - val_loss: 0.3216\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.3194\n"
     ]
    }
   ],
   "source": [
    "# 10 esta bien. Lo pondemos a 5 para el ejercicio\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, \n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard\n",
    "Keras tiene implementado un dashboard para monitorizar las ejecuciones del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Crea este directorio\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "# Guarda una carpeta nueva con la fecha de la ejecucion\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3057 - val_loss: 0.3346\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3050 - val_loss: 0.3297\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3034 - val_loss: 0.3190\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3027 - val_loss: 0.3218\n",
      "Epoch 5/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3047 - val_loss: 0.3214\n",
      "Epoch 6/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3020 - val_loss: 0.3210\n",
      "Epoch 7/50\n",
      "363/363 [==============================] - 0s 969us/step - loss: 0.3005 - val_loss: 0.3172\n",
      "Epoch 8/50\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.3022 - val_loss: 0.3181\n",
      "Epoch 9/50\n",
      "363/363 [==============================] - 0s 905us/step - loss: 0.3114 - val_loss: 0.3178\n",
      "Epoch 10/50\n",
      "363/363 [==============================] - 0s 901us/step - loss: 0.2999 - val_loss: 0.3331\n",
      "Epoch 11/50\n",
      "363/363 [==============================] - 0s 933us/step - loss: 0.3013 - val_loss: 0.3198\n",
      "Epoch 12/50\n",
      "363/363 [==============================] - 0s 924us/step - loss: 0.2989 - val_loss: 0.3236\n",
      "Epoch 13/50\n",
      "363/363 [==============================] - 0s 913us/step - loss: 0.2986 - val_loss: 0.3165\n",
      "Epoch 14/50\n",
      "363/363 [==============================] - 0s 943us/step - loss: 0.2987 - val_loss: 0.3194\n",
      "Epoch 15/50\n",
      "363/363 [==============================] - 0s 903us/step - loss: 0.3137 - val_loss: 0.3365\n",
      "Epoch 16/50\n",
      "363/363 [==============================] - 0s 927us/step - loss: 0.3032 - val_loss: 0.3199\n",
      "Epoch 17/50\n",
      "363/363 [==============================] - 0s 955us/step - loss: 0.2976 - val_loss: 0.3162\n",
      "Epoch 18/50\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.2964 - val_loss: 0.3266\n",
      "Epoch 19/50\n",
      "363/363 [==============================] - 0s 969us/step - loss: 0.2970 - val_loss: 0.3185\n",
      "Epoch 20/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2996 - val_loss: 0.3312\n",
      "Epoch 21/50\n",
      "363/363 [==============================] - 0s 949us/step - loss: 0.3095 - val_loss: 0.3145\n",
      "Epoch 22/50\n",
      "363/363 [==============================] - 0s 938us/step - loss: 0.3001 - val_loss: 0.3204\n",
      "Epoch 23/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2959 - val_loss: 0.3186\n",
      "Epoch 24/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2943 - val_loss: 0.3149\n",
      "Epoch 25/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2982 - val_loss: 0.3195\n",
      "Epoch 26/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2953 - val_loss: 0.3229\n",
      "Epoch 27/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2945 - val_loss: 0.3207\n",
      "Epoch 28/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2968 - val_loss: 0.3273\n",
      "Epoch 29/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2933 - val_loss: 0.3140\n",
      "Epoch 30/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3224 - val_loss: 0.3274\n",
      "Epoch 31/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.3137\n",
      "Epoch 32/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2927 - val_loss: 0.3272\n",
      "Epoch 33/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2942 - val_loss: 0.3141\n",
      "Epoch 34/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2907 - val_loss: 0.3284\n",
      "Epoch 35/50\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2944 - val_loss: 0.3216\n",
      "Epoch 36/50\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.2897 - val_loss: 0.3257\n",
      "Epoch 37/50\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.2921 - val_loss: 0.3229\n",
      "Epoch 38/50\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.2909 - val_loss: 0.3254\n",
      "Epoch 39/50\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.2895 - val_loss: 0.3191\n",
      "Epoch 40/50\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.2905 - val_loss: 0.3287\n",
      "Epoch 41/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2876 - val_loss: 0.3133\n",
      "Epoch 42/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2890 - val_loss: 0.3183\n",
      "Epoch 43/50\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2895 - val_loss: 0.3282\n",
      "Epoch 44/50\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.2896 - val_loss: 0.3144\n",
      "Epoch 45/50\n",
      "363/363 [==============================] - 0s 942us/step - loss: 0.2885 - val_loss: 0.3389\n",
      "Epoch 46/50\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.2938 - val_loss: 0.3144\n",
      "Epoch 47/50\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.2875 - val_loss: 0.3348\n",
      "Epoch 48/50\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.2876 - val_loss: 0.3059\n",
      "Epoch 49/50\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.2875 - val_loss: 0.3258\n",
      "Epoch 50/50\n",
      "363/363 [==============================] - 0s 902us/step - loss: 0.2894 - val_loss: 0.3106\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPara lanzarlo desde el jupyter notebook\\n%load_ext tensorboard\\n%tensorboard --logdir=./my_logs --port=6006\\n\\nPara lanzarlo desde el terminal, hay que estar en la carpeta de los logs\\ntensorboard --logdir=./my_logs --port=6006\\n\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Para lanzarlo desde el jupyter notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "Para lanzarlo desde el terminal, hay que estar en la carpeta de los logs\n",
    "tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 22404), started 1 day, 15:40:48 ago. (Use '!kill 22404' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8cc26bf790b33bd1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8cc26bf790b33bd1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
