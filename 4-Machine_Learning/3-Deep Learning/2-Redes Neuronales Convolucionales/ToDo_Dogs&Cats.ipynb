{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Convolucionales\n",
    "#### Ejemplo clasificación de perros y gatos para CAPTCHA\n",
    "\n",
    "Este notebook utiliza datos de la [competición de Kaggle Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats/overview). En esta competicion se utiliza Asirra (Animal Species Image Recognition for Restricting Access), CAPTCHA que sirve para diferenciar entre una persona o una máquina accediendo a una página web. Este tipo de \"pruebas\" se utilizan para evitar emails de spam, y ataques por fuerza bruta contra servidores.\n",
    "\n",
    "En este notebook vamos a probar que hay técnicas de clasificado automáticas de imágenes mediante redes neuronales, que con las que se intenta saltar CAPTCHA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe76d1d1ded592430e7548feacfa38dc42f085d9"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image_dataset import ImageDataGenerator, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Constants\n",
    "Tendremos una serie de constantes como las dimensiones de las imágenes, que serán fijas a lo largo de todo el notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH=32\n",
    "IMAGE_HEIGHT=32\n",
    "IMAGE_CHANNELS=3\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 5\n",
    "ROOT_PATH = \"/Users/federicoruizruiz/Documents/TheBridge_Bootcamp/kaggle-data/cats-dogs/\"\n",
    "\n",
    "\"\"\"TRAIN_PATH_TOT = ROOT_PATH + \"train\\\\train\\\\\"\n",
    "TEST_PATH_TOT = ROOT_PATH + \"test\\\\test\\\\\"\n",
    "\n",
    "MINI_TRAIN_PATH = ROOT_PATH + \"mini_train\\\\train\\\\\"\n",
    "MINI_TEST_PATH = ROOT_PATH + \"mini_test\\\\test1\\\\\"\"\"\n",
    "\n",
    "TRAIN_PATH = ROOT_PATH + 'cat_dogs_img/train/'\n",
    "TEST_PATH = ROOT_PATH + 'cat_dogs_img/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7335a579cc0268fba5d34d6f7558f33c187eedb3"
   },
   "source": [
    "# Prepare Training Data\n",
    "1. Descárgate el dataset de train de [la competición de Kaggle](https://www.kaggle.com/c/dogs-vs-cats/overview).\n",
    "2. Descomprime el dataset y guardalo en la ruta que quieras del ordenador. Por supuesto, NO en la carpeta donde esté el repositorio\n",
    "3. En este punto vamos guardar en una lista las etiquetas de cada foto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ws/4s9tjczx71l06gt4dkp8q4vw0000gn/T/ipykernel_14187/2538135577.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##### CODE #####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "##### CODE #####\n",
    "filenames = os.listdir(TRAIN_PATH)\n",
    "\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "915bb9ba7063ab4d5c07c542419ae119003a5f98"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dog.8011.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat.5077.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog.7322.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat.2718.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat.10151.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>dog.8008.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>dog.1992.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>dog.12412.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>cat.2701.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>cat.10148.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  category\n",
       "0       dog.8011.jpg         1\n",
       "1       cat.5077.jpg         0\n",
       "2       dog.7322.jpg         1\n",
       "3       cat.2718.jpg         0\n",
       "4      cat.10151.jpg         0\n",
       "...              ...       ...\n",
       "24995   dog.8008.jpg         1\n",
       "24996   dog.1992.jpg         1\n",
       "24997  dog.12412.jpg         1\n",
       "24998   cat.2701.jpg         0\n",
       "24999  cat.10148.jpg         0\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a999484fc35b73373fafe2253ae9db7ff46fdb90"
   },
   "source": [
    "### See Total In count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "fa26f0bc7a6d835a24989790b20f3c6f32946f45"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['category'].value_counts().plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "400a293df3c8499059d9175f3915187074efd971"
   },
   "source": [
    "# See sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ws/4s9tjczx71l06gt4dkp8q4vw0000gn/T/ipykernel_7492/1819209774.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##### CODE #####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#pip install opencv-python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "#pip install opencv-python\n",
    "\n",
    "sample = random.choice(filenames)\n",
    "image = imread(TRAIN_PATH + sample)\n",
    "\n",
    "print(image.shape)\n",
    "print(np.max(image))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una imagen no es mas que un array de HxWxC píxeles, siendo H(Height) y W(Width) las dimensiones de resolución de la imagen, y C el número de canales. Habrá tres valores por píxel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize image\n",
    "Cargar todas las imágenes a la vez es un problema ya que son un total de 25000 (unos 500MB la carpeta de train). Este proceso require mucha memoria, por lo que tendremos que aplicarle un resize a cada imagen para bajarlas de resolución. Esto también nos sirve para solventar el problema de tener imágenes con distintas resoluciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "##### CODE #####\n",
    "\n",
    "\n",
    "print(\"Tamaño imagen original:\", image.shape)\n",
    "print(\"Tamaño imagen reshape:\", imagesmall.shape)\n",
    "print(\"Maximo valor por pixel:\", np.max(imagesmall))\n",
    "\n",
    "# Original image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "\n",
    "# Resized image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(imagesmall);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color\n",
    "Podríamos cargar las imágenes como blanco y negro, de esta forma se reduciría el espacio de features considerablemente al contar con un único canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = random.choice(filenames)\n",
    "\n",
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "Llega el momento de cargar los datos. Ya no estan sencillo como cuando teníamos datasets en CSVs puesto que ahora hay que cargar miles de archivos en memoria en este notebook. Para ello necesitaremos un programa iterativo que vaya recorriendo los archivos de la carpeta, cargarlos como array de numpy y almacenarlos en un objeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, im_size):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    ##### CODE #####\n",
    "\n",
    "    return np.array(X), np.array(Y)\n",
    "    \n",
    "\n",
    "X_train, y_train = read_data(TRAIN_PATH, IMAGE_SIZE)\n",
    "X_test, y_test = read_data(TEST_PATH, IMAGE_SIZE)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0].shape)\n",
    "plt.imshow(X_train[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized data\n",
    "Normalizar los datos hará que entrene mucho mejor la red, al estar todos los pixeles en la misma escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Min:\", np.min(X_train))\n",
    "print(\"Max:\", np.max(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "print(\"Min:\", np.min(X_train))\n",
    "print(\"Max:\", np.max(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle data\n",
    "Como hemos cargado los datos de manera ordenada (primero gatos y luego perros), tendremos que desordenarlos para asegurarnos de que no haya ningún sesgo en el entrenamiento ni en la selección de datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data\n",
    "Podemos guardar los arrays de numpy en un archivo `.npz`, de tal manera que luego sea más rápido importarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cargar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b244e6b7715a04fc6df92dd6dfa3d35c473ca600"
   },
   "source": [
    "# Build Model\n",
    "\n",
    "<img src=\"https://i.imgur.com/ebkMGGu.jpg\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Conv Layer**: extraerá diferentes features de las imagenes\n",
    "* **Pooling Layer**: Reduce las dimensiones de las imágenes tras una capa convolucional\n",
    "* **Fully Connected Layer**: Tras las capas convolucionales, aplanamos las features y las introducimos como entrada de una red neuronal normal.\n",
    "* **Output Layer**: Las predicciones de la red\n",
    "\n",
    "Para el loss y la metrica, se puede usar un binary_crossentropy, al ser un target binario. O "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bd496f6c65888a969be3703135b0b03a8a1190c8"
   },
   "source": [
    "# Callbacks\n",
    "#### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9aa032f0f6da539d23918890d2d131cc3aac8c7a"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "Probemos los datos en el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_test[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'})\n",
    "\n",
    "print(\"Categorias:\", df['category'].unique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4252cce168ab65f88e44a8ebc2672607bc852af4"
   },
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "23d923dba747f8b47dc75569244cecc6f70df321"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i in range(0, 15):\n",
    "    plt.subplot(5, 3, i+1)\n",
    "    for X_batch, Y_batch in example_generator:\n",
    "        image = X_batch[0]\n",
    "        plt.imshow(image)\n",
    "        break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4eeb7af8dcf02c4ef5ca744c8305c51a2f5cedef"
   },
   "outputs": [],
   "source": [
    "train_df, validate_df = train_test_split(df,\n",
    "                                         test_size=0.20,\n",
    "                                         random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae3dec0361f0443132d0309d3b883ee80070cf9f"
   },
   "outputs": [],
   "source": [
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "\n",
    "print(\"Shape train\", total_train)\n",
    "print(\"Shape validation\", total_validate)\n",
    "validate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff760be9104f7d9492467b8d9d3405011aa77d11"
   },
   "source": [
    "# Training Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4d1c7818703a8a4bac5c036fdea45972aa9e5e9e"
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    TRAIN_PATH, \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    class_mode='binary',\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "859c7b2857939c19fd2e3bb32839c9f7deb5aa3f"
   },
   "source": [
    "### Validation Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7925e16bcacc89f4484fb6fe47e54d6420af732e"
   },
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    TRAIN_PATH, \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    class_mode='binary',\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5cd8df64e794ed17de326b613a9819e7da977a0e"
   },
   "source": [
    "# Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0836a4cc8aa0abf603e0f96573c0c4ff383ad56b"
   },
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b76c0a9040bc0babf0a453e567e41e22f8a1e0e"
   },
   "source": [
    "# Virtualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79055f2dc3e2abb47bea758e0464c86ca42ab431"
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "ax1.set_xticks(np.arange(1, EPOCHS, 1))\n",
    "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "ax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "ax2.set_xticks(np.arange(1, EPOCHS, 1))\n",
    "\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
